\documentclass{article}
\usepackage{placeins}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{listings}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{booktabs, siunitx}
\usepackage{geometry}
\usepackage{minted}
\usepackage{indentfirst}
\usepackage{caption}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage[backend=biber, style=alphabetic]{biblatex}
\usepackage[svgnames,table]{xcolor}

\addbibresource{ref.bib}
\usemintedstyle{emacs}
\geometry{
 a4paper,
 total={170mm,257mm},
 left=20mm,
 top=20mm,
 }
\graphicspath{ {./images/} }

\title{
Assignment 4 Report
}
\author{Tanat Tangun 630610737}
\date{November 2022}

\begin{document}
\maketitle
This report is about the result of my implementation of Paricles Swarm Optimization (PSO) for optimizing the MLP on 
Rust language for 261456 - INTRO COMP INTEL FOR CPE class
assignment.
If you are interested to know how I implement PSO and use it to optimize the MLP
, you can see the source code on my 
\href{https://github.com/RiwEZ/MLPOnRust}{Github repository} or in this document appendix.

\section*{Problem}
Given the \href{https://archive.ics.uci.edu/ml/datasets/air+quality}{AirQualityUCI} dataset from UCI machine learning
repository which has 9358 samples and 14 attributes as follows:
\begin{enumerate}
    \item {Date (DD/MM/YYYY)}
    \item {Time (HH.MM.SS)}
    \item {True hourly averaged concentration CO in $\text{mg}/m^3$ (reference analyzer)}
    \item {\underline{PT08.S1 (tin oxide) hourly averaged sensor response (nominally CO targeted)}}
    \item {True hourly averaged overall Non Metanic HydroCarbons concentration in $\text{microg}/m^3$ (reference analyzer)}
    \item {\textbf{True hourly averaged Benzene concentration in $\text{microg}/m^3$ (reference analyzer)}}
    \item {\underline{PT08.S2 (titania) hourly averaged sensor response (nominally NMHC targeted)}}
    \item {True hourly averaged NOx concentration in ppb (reference analyzer)}
    \item {\underline{PT08.S3 (tungsten oxide) hourly averaged sensor response (nominally NOx targeted)}}
    \item {True hourly averaged NO2 concentration in $\text{microg}/m^3$ (reference analyzer)}
    \item {\underline{PT08.S4 (tungsten oxide) hourly averaged sensor response (nominally NO2 targeted)}}
    \item {\underline{PT08.S5 (indium oxide) hourly averaged sensor response (nominally O3 targeted)}}
    \item {\underline{Temperature in Â°C}}
    \item {\underline{Relative Humidity (\%)}}
    \item {\underline{AH Absolute Humidity}}
\end{enumerate}
We want to use the underlined attributes 4, 7, 9, 11, 12, 13, 14, 15 to predict attribute 6 (benzene concentration) 
in next 5 days and next 10 days.

\section*{Dataset Preparation}
We will refer to the underlined attributes as ``features" and attribute 6 (benzene concentration) as ``desired output". 
The dataset preparation process will follow these steps (implementation on source code \ref{src:data}): 
\begin{enumerate}
    \item {Load the dataset from the csv file and removing any samples that has a missing value 
    (missing value are tagged with -200 value).}
    \item {Match each features with desired output of the next 5 and 10 days, then we will get
    an array of tuple (features, next 5 days desired output) and tuple (features, next 10 days desired output).}
\end{enumerate}
The array of tuple (features, next 5 days desired output) and tuple (features, next 10 days desired output) will be used 
for training our MLP.

\section*{Particles Swarm Optimization}
\subsection*{Particle Representation}
A particle is represented by a list of weights and biases of MLP. 
We use weights and bias of top node to bottom node of each layer to create one individual, 
for an example: from 3-2-1 network in \cref*{fig:1} a particle is represented by (w1, w2, w3, b1, w4, w5, w6, b2, w7, w8, b3).

\begin{figure}[ht]
    \centering
    \includegraphics[scale = 0.25]{nn_example.jpg}
    \caption{The 3-2-1 network.}
    \label{fig:1}
\end{figure}

\subsection*{Full Process}
Using 10\% cross-validation, and preprocess each iteration training and validation set with min-max normalization. The min-max 
normalization process is done by for each feature $f$ on training set we find $max(f)$ and $min(f)$ then for each datapoint $f_x$
we compute new datapoint on both training set and validation set $f_x' = \frac{f_x - min(f)}{max(f) - min(f)}$, this will guarantee
that we applied the min-max normalization using $min$ and $max$ from training set on both training set and validation set. Next, for  
each cross-validation iteration we follow the local best method described on \cite{sansanee} page 138 which is 
(implementation on source code \ref{src:air} and \ref{src:swarm}):
\begin{enumerate}
    \item {Initialize the particles population $P(t)$ at $t = 0$ which has 5 groups of 4 particles and 
    for each particle we set the weights to a random number in range [-1.0, 1.0], and bias of each node to to 1.0.
    }
    \item {For each group $j$ and each particle $i$ in group $j$ do:
        \begin{enumerate}
            \item Evaluate its performance $F$ using its current position $x_i(t)$ through all samples in training set.
            \item {Compare evaluation result from (a) with its best evaluation result $\text{pbest}_i$.
                \begin{algorithmic}
                    \If{$F(x_i(t)) < \text{pbest}_i$}
                        \State $\text{pbest}_i = F(x_i(t))$ 
                        \State $x_i^{\text{pbest}} = x_i(t)$
                    \EndIf
                \end{algorithmic}
                }  
            \item {Compare evaluation result from (a) with the group's $\text{lbest}_j$.
                \begin{algorithmic}
                    \If{$F(x_i(t)) < \text{lbest}_j$}
                        \State $\text{lbest}_j = F(x_i(t))$ 
                        \State $x_{\text{lbest}_j} = x_i(t)$
                    \EndIf
                \end{algorithmic}
                }
            \item {Update the speed of $i$ by using following equation:
            $$
                v_i(t) = v_i(t-1) + \rho_1(x_i^{pbest} - x_i(t)) + \rho_2(x_{\text{lbest}_j} - x_i(t))
            $$
            where $\rho_1 = r_1c_1$ and $\rho_2 = r_2c_2$  with $c_1 = 1.0$, $c_2 = 1.5$ and $r_1$, $r_2$ are a random 
            number from uniform distribution of $(0, 1)$
            }
            \item {Update $x_i$ by $x_i(t) = x_i(t - 1) + v_i(t)$ and set $t = t + 1$} 
        \end{enumerate}}
    \item Repeat step 2. until $t = 100$.
\end{enumerate}

\section*{Training Result}
For both next 5 days dataset and next 10 days dataset, we will experiment with 3 models to see if their training result will 
have any significant differences in training time and MAE (mean absolute error). The 3 models (implementation on source code \ref{src:air})
are 
\begin{itemize}
    \item {\textbf{air-8-4-1}: The base model that contains 8 input nodes, 1 hidden layer with 4 nodes, and 1 output node. The result 
    is shown on \cref{fig:2} and \cref{fig:3} }
    \item {\textbf{air-8-1-1}: A smaller model with 8 input nodes, 1 hidden layer with 1 nodes, and 1 output node. The result 
    is shown on \cref{fig:4} and \cref{fig:5}}
    \item {\textbf{air-8-8-4-1}: A larger model with 8 input nodes, 2 hidden layers with 8 and 4 nodes, and 1 output node. The result
    is shown on \cref{fig:6} and \cref{fig:7}}
\end{itemize} 
which the output node use linear activation function and other nodes use relu activation function. We use Rust compiler with 
release profile to build and run all training.

\section*{Analysis}
From \cref{table:1} and \cref{table:2}, we can see that every model train on both next 5 days dataset and next 10 days dataset have 
a similar validation set MAE and similar training process as we can see in \cref{fig:2}, \cref{fig:3}, \cref{fig:4}, \cref{fig:5}, 
\cref{fig:6} and \cref{fig:7}. The training process from those figures shows that every model seem to converge to MAE $\approx 5$ in 
less than $t = 25$ and can't find a position to make MAE lower. The reason why every model can not make MAE lower maybe is because 
this dataset need a much more complex MLP structure to create a better regression model. Next, the training time of each model 
is less with the less complex it is and more with the more complex it is, showing that PSO training times correlate with MLP complexity.  
\begin{table}[htp]
	\centering
	\begin{tabular}{l S[table-format=2.3] S[table-format=2.1]}
		\toprule
        \multicolumn{1}{c}{Model} & {Training Time (seconds)} & {Mean Absolute Error (MAE)} \\
        \midrule
        air-8-4-1 & 62.233 & 5.194 \\
        air-8-1-1 & 58.504  & 5.184 \\
        air-8-8-4-1 & 81.596 & 5.216 \\
        \bottomrule
    \end{tabular} 
	\caption{Training time and validation set MAE of next 5 days dataset (red line on 
		\cref{fig:2b}, \cref{fig:4b}, and \cref{fig:6b}) of each model.}
	\label{table:1}
\end{table}
\begin{table}[htp]
	\centering
	\begin{tabular}{l S[table-format=2.3] S[table-format=1.3]}
		\toprule
        \multicolumn{1}{c}{Model} & {Training Time (seconds)} & {Mean Absolute Error (MAE)} \\
        \midrule
        air-8-4-1 & 61.401 & 5.107 \\
        air-8-1-1 & 53.990 & 5.122 \\
        air-8-8-4-1 & 78.985 & 5.256 \\
        \bottomrule
    \end{tabular} 
	\caption{Training time and validation set MAE of next 10 days dataset (red line on 
		\cref{fig:3b}, \cref{fig:5b}, and \cref{fig:7b}) of each model.}
	\label{table:2}
\end{table}

\section*{Summary}
Particles Swarm Optimization (PSO) can be used for training MLP with an okay performance within a reasonable times as shown on our
experiment. Training the regression MLP for AirQualityUCI dataset seem to be a challenging problem with PSO, this may need a further
investigation. 
Finally, Rust is a great languate to implement PSO with how fast it is and how easy it is to write a memory-safe program.

\printbibliography

\include{appendix.tex}

\end{document}